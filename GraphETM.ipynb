{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GraphETM Dev Notebook",
   "id": "75852b8e51af2279"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T18:48:06.412798Z",
     "start_time": "2025-07-17T18:47:51.454353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Imports\n",
    "## Local\n",
    "from graphetm.model import GraphETM\n",
    "from graphetm.trainers.graphetm_trainer import GraphETMTrainer\n",
    "from graphetm.loss import GraphReconLoss\n",
    "from utils.datasets import ETMDataset\n",
    "\n",
    "## External\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_geometric as pyg\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plot\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import wandb\n",
    "\n",
    "import torch.profiler\n",
    "\n",
    "### Parameters\n",
    "wandb.login()"
   ],
   "id": "b594b9c64bb75b73",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mloicduch\u001B[0m (\u001B[33mloicduch-mcgill-university\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T18:48:19.550999Z",
     "start_time": "2025-07-17T18:48:19.541969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Seeds\n",
    "pyg.seed_everything(10) # random, np, torch, torch.cuda"
   ],
   "id": "557db418d1a5cca5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "# Training"
   ],
   "id": "dc5337a766dbb8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T18:48:20.162197Z",
     "start_time": "2025-07-17T18:48:20.134116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ],
   "id": "253bea9b7ac31024",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T18:48:21.108607Z",
     "start_time": "2025-07-17T18:48:20.801853Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Data\n",
    "test_size = 0.2\n",
    "\n",
    "# Load metadata\n",
    "input_sc = pd.read_csv('inputs/GraphETM/optional/input_PBMC.csv')\n",
    "input_ehr = pd.read_csv('inputs/GraphETM/optional/input_EHR.csv')\n",
    "\n",
    "# Load labels\n",
    "labels_sc  = torch.tensor(np.load('inputs/GraphETM/labels/sc_labels_num.npy'))\n",
    "labels_ehr = torch.tensor(np.load('inputs/GraphETM/labels/ehr_labels_num.npy'))\n",
    "sc_categories  = np.load('inputs/GraphETM/labels/sc_categories.npy')\n",
    "ehr_categories = np.load('inputs/GraphETM/labels/ehr_categories.npy')\n",
    "\n",
    "# Load Rho (Graph Embeddings)\n",
    "sc_indices   = np.load('inputs/GraphETM/id_embed_sc.npy')\n",
    "ehr_indices  = np.load('inputs/GraphETM/id_embed_ehr.npy')\n",
    "drug_indices = np.load('inputs/GraphETM/id_embed_drugs.npy') # Only decoding\n",
    "\n",
    "embedding_full = torch.load('inputs/GraphETM/embedding_full.pt', weights_only=False) # V x L\n",
    "edge_index = torch.load('inputs/GraphETM/edge_index.pt', weights_only=True)\n",
    "\n",
    "# Load Input Data\n",
    "X_sc  = torch.load('inputs/GraphETM/X_sc.pt',  weights_only=False) # (num_samples (cells), num_genes)\n",
    "X_ehr = torch.load('inputs/GraphETM/X_ehr.pt', weights_only=False)\n",
    "\n",
    "X_sc,  X_sc_val , _, val_labels_sc  = train_test_split(X_sc , labels_sc , test_size=test_size, random_state=0, stratify=labels_sc)\n",
    "X_ehr, X_ehr_val, _, val_labels_ehr = train_test_split(X_ehr, labels_ehr, test_size=test_size, random_state=0, stratify=labels_ehr)\n",
    "\n",
    "# Validation Dataset (for labels)\n",
    "val_dataset_sc  = ETMDataset(X_sc_val, val_labels_sc)\n",
    "val_dataset_ehr = ETMDataset(X_ehr_val, val_labels_ehr)"
   ],
   "id": "e72ba919c7a2536a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-17T02:46:06.546699Z",
     "start_time": "2025-07-17T02:46:03.442446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Parameters\n",
    "config = {\n",
    "    ### ETM Model Config\n",
    "    'model': dict(\n",
    "        num_topics = 40,    # Original: K = 15\n",
    "        theta_act = 'relu', # Original: relu\n",
    "        dropout = 0.1,      # Original: 0.1\n",
    "        graph_recon_loss = GraphReconLoss(num_neg_samples = 10000),\n",
    "        gcn_params = {'hidden_dim': embedding_full.shape[1] * 2},\n",
    "        encoder_params = {\n",
    "            'sc': { # Encoder SC\n",
    "                'vocab_size': X_sc.shape[1],\n",
    "                'encoder_hidden_size': embedding_full.shape[1]},\n",
    "            'ehr': { # Encoder EHR\n",
    "                'vocab_size': X_ehr.shape[1],\n",
    "                'encoder_hidden_size': embedding_full.shape[1]}},\n",
    "    ),\n",
    "\n",
    "    'optimizer': dict(\n",
    "        model = torch.optim.Adam,\n",
    "        lr_graph = 1e-4,\n",
    "        lr_etm_sc = 1e-7,\n",
    "        lr_etm_ehr = 1e-6,\n",
    "        # lr = 1e-5, # Original: 1e-4\n",
    "    ),\n",
    "\n",
    "    'training': dict(\n",
    "        epochs = 50,\n",
    "        graph_loss_weight = 1e-2, # Original: 1e-3\n",
    "        kld_max = 1e-6,\n",
    "        kld_annealing_duration = 5 # Original: 5\n",
    "    ),\n",
    "\n",
    "    'dataloader': dict(\n",
    "        batch_size = 64,\n",
    "        shuffle = False\n",
    "    ),\n",
    "\n",
    "    'device': device,\n",
    "}\n",
    "\n",
    "### Model\n",
    "model = GraphETM(\n",
    "    **config['model'],\n",
    "    ## Embedding Parameters\n",
    "    embedding  = embedding_full,\n",
    "    edge_index = edge_index,\n",
    "    id_embed_sc  = sc_indices,\n",
    "    id_embed_ehr = ehr_indices,\n",
    "    ## Params\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "trainer = GraphETMTrainer(\n",
    "    ## Models\n",
    "    model = model,\n",
    "    ## Data Parameters\n",
    "    dataloader_sc  = DataLoader(**config['dataloader'], dataset = X_sc ), # Dataloaders\n",
    "    dataloader_ehr = DataLoader(**config['dataloader'], dataset = X_ehr),\n",
    "    val_dataloader_sc  = DataLoader(**config['dataloader'], dataset = val_dataset_sc),\n",
    "    val_dataloader_ehr = DataLoader(**config['dataloader'], dataset = val_dataset_ehr),\n",
    "    ## Labels Parameters\n",
    "    # n_clusters_sc  = 10,\n",
    "    # n_clusters_ehr = 5,\n",
    "    ## Params\n",
    "    device = device,\n",
    "    wandb_run = wandb.init(\n",
    "        project = 'GraphETM',\n",
    "        group = 'Revision 5',\n",
    "        name = 'graph_2layers',\n",
    "        config=config, save_code=True) # Start Wandb\n",
    ")\n",
    "\n",
    "### Training\n",
    "model.train(\n",
    "    optimizer =\n",
    "    config['optimizer']['model'](\n",
    "        [{'params': model.etm_model.enc_sc.parameters() , 'lr': config['optimizer']['lr_etm_sc'] },\n",
    "         {'params': model.etm_model.dec_sc.parameters() , 'lr': config['optimizer']['lr_etm_sc'] },\n",
    "         {'params': model.etm_model.enc_ehr.parameters(), 'lr': config['optimizer']['lr_etm_ehr']},\n",
    "         {'params': model.etm_model.dec_ehr.parameters(), 'lr': config['optimizer']['lr_etm_ehr']},\n",
    "         {'params': model.graph_model.parameters(), 'lr': config['optimizer']['lr_graph']}]\n",
    "    ),\n",
    "    **config['training'])"
   ],
   "id": "5976a6a312ce2e02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/tmp/pycharm_project_774/wandb/run-20250717_024603-l5q1qapb</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/loicduch-mcgill-university/GraphETM/runs/l5q1qapb' target=\"_blank\">graph_2layers</a></strong> to <a href='https://wandb.ai/loicduch-mcgill-university/GraphETM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/loicduch-mcgill-university/GraphETM' target=\"_blank\">https://wandb.ai/loicduch-mcgill-university/GraphETM</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/loicduch-mcgill-university/GraphETM/runs/l5q1qapb' target=\"_blank\">https://wandb.ai/loicduch-mcgill-university/GraphETM/runs/l5q1qapb</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training GraphETM:   0%|          | 0/50 [00:00<?, ?epoch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4bcc5a03b63e4422bbc2b2869ee2a2a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graph_2layers</strong> at: <a href='https://wandb.ai/loicduch-mcgill-university/GraphETM/runs/l5q1qapb' target=\"_blank\">https://wandb.ai/loicduch-mcgill-university/GraphETM/runs/l5q1qapb</a><br> View project at: <a href='https://wandb.ai/loicduch-mcgill-university/GraphETM' target=\"_blank\">https://wandb.ai/loicduch-mcgill-university/GraphETM</a><br>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20250717_024603-l5q1qapb/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (122777x64 and 128x64)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 76\u001B[39m\n\u001B[32m     49\u001B[39m model = GraphETM(\n\u001B[32m     50\u001B[39m     etm_model_cfg   = config[\u001B[33m'\u001B[39m\u001B[33metm_model\u001B[39m\u001B[33m'\u001B[39m],   \u001B[38;5;66;03m# ETM Model config\u001B[39;00m\n\u001B[32m     51\u001B[39m     graph_model_cfg = config[\u001B[33m'\u001B[39m\u001B[33mgraph_model\u001B[39m\u001B[33m'\u001B[39m], \u001B[38;5;66;03m# Graph Model config\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     72\u001B[39m         config=config, save_code=\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;66;03m# Start Wandb\u001B[39;00m\n\u001B[32m     73\u001B[39m )\n\u001B[32m     75\u001B[39m \u001B[38;5;66;03m### Training\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m76\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\n\u001B[32m     78\u001B[39m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43moptimizer\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mmodel\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     79\u001B[39m \u001B[43m        \u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mparams\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43metm_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43menc_sc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43moptimizer\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr_etm_sc\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[43m         \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mparams\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43metm_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdec_sc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43moptimizer\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr_etm_sc\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     81\u001B[39m \u001B[43m         \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mparams\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43metm_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43menc_ehr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43moptimizer\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr_etm_ehr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     82\u001B[39m \u001B[43m         \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mparams\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43metm_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdec_ehr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43moptimizer\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr_etm_ehr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     83\u001B[39m \u001B[43m         \u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mparams\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgraph_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43moptimizer\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mlr_graph\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     84\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     85\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtraining\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/tmp/pycharm_project_774/model/graphetm.py:178\u001B[39m, in \u001B[36mGraphETM.train\u001B[39m\u001B[34m(self, epochs, optimizer, recon_loss_weight, graph_loss_weight, kld_max, kld_annealing_duration, verbose)\u001B[39m\n\u001B[32m    175\u001B[39m bow_sc, bow_ehr = bow_sc.to(\u001B[38;5;28mself\u001B[39m.device), bow_ehr.to(\u001B[38;5;28mself\u001B[39m.device)\n\u001B[32m    177\u001B[39m \u001B[38;5;66;03m# Filter: Forward\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m rho_full_new = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgraph_model\u001B[49m\u001B[43m.\u001B[49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# [N_total, L]\u001B[39;00m\n\u001B[32m    179\u001B[39m graph_loss = \u001B[38;5;28mself\u001B[39m.graph_recon_loss(rho_full_new, edge_index=\u001B[38;5;28mself\u001B[39m.edge_index) * graph_loss_weight\n\u001B[32m    181\u001B[39m rho_sc  = rho_full_new[\u001B[38;5;28mself\u001B[39m.id_embed_sc ] \u001B[38;5;66;03m# [V_sc , L]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/tmp/pycharm_project_774/model/graph_model.py:27\u001B[39m, in \u001B[36mGraphModel.forward\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m): \u001B[38;5;66;03m# TODO: Normalize/dropout potentially to be added.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m     rho_full1 = F.relu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrho_full0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;66;03m# [N_total, L]\u001B[39;00m\n\u001B[32m     28\u001B[39m     rho_full2 = F.relu(\u001B[38;5;28mself\u001B[39m.conv2(rho_full1, \u001B[38;5;28mself\u001B[39m.edge_index))\n\u001B[32m     29\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m rho_full2\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/conv/gcn_conv.py:260\u001B[39m, in \u001B[36mGCNConv.forward\u001B[39m\u001B[34m(self, x, edge_index, edge_weight)\u001B[39m\n\u001B[32m    257\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    258\u001B[39m             edge_index = cache\n\u001B[32m--> \u001B[39m\u001B[32m260\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    262\u001B[39m \u001B[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001B[39;00m\n\u001B[32m    263\u001B[39m out = \u001B[38;5;28mself\u001B[39m.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/lib/python3.13/site-packages/torch_geometric/nn/dense/linear.py:147\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m    141\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) -> Tensor:\n\u001B[32m    142\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Forward pass.\u001B[39;00m\n\u001B[32m    143\u001B[39m \n\u001B[32m    144\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m    145\u001B[39m \u001B[33;03m        x (torch.Tensor): The input features.\u001B[39;00m\n\u001B[32m    146\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mRuntimeError\u001B[39m: mat1 and mat2 shapes cannot be multiplied (122777x64 and 128x64)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### FUNCTION TOP_K\n",
    "TOP_K = 5\n",
    "\n",
    "# TODO REVERSE RANKING + CORRESPONDING\n",
    "\n",
    "def top_k_per_topic(input_df, modality, k=5):\n",
    "    beta = model.etm_model.get_beta(modality=modality)\n",
    "\n",
    "    top_k_indices = np.argsort(beta, axis=1)[:, -k:]\n",
    "    top_k_indices = top_k_indices.flatten()\n",
    "    top_k = input_df.columns[top_k_indices]\n",
    "\n",
    "    prob = beta[:, top_k_indices].T\n",
    "    return pd.DataFrame(prob, index=top_k)\n",
    "\n",
    "### GET TOP K PER TOPIC\n",
    "sc_prob_df = top_k_per_topic(input_df=input_sc, modality='sc', k=TOP_K) # SC\n",
    "ehr_prob_df = top_k_per_topic(input_df=input_ehr, modality='ehr', k=TOP_K) # EHR\n",
    "\n",
    "### PLOT\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    horizontal_spacing=0.06,\n",
    "    subplot_titles=['Top Gene per Topics', 'Top ICD-9 Code per Topics'],\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_white',\n",
    "    width=1200, height=1500,\n",
    "    font=dict(color='black', size=10),\n",
    ")\n",
    "\n",
    "# PARAMS\n",
    "heatmap_params = dict(\n",
    "    colorscale='OrRd',\n",
    "    xgap=0.9,\n",
    "    ygap=0.9,\n",
    ")\n",
    "\n",
    "yaxes_params = dict(\n",
    "    tickfont=dict(size=10, color='black')\n",
    ")\n",
    "\n",
    "# SC Plot\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        name='SC',\n",
    "        z=sc_prob_df.values,\n",
    "        x=sc_prob_df.columns,\n",
    "        y=list(range(len(sc_prob_df.index))),\n",
    "        **heatmap_params\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    tickvals=list(range(len(sc_prob_df.index))),\n",
    "    ticktext=sc_prob_df.index,\n",
    "    autorange='reversed', type='category',\n",
    "    row=1, col=1,\n",
    "    **yaxes_params\n",
    ")\n",
    "\n",
    "# EHR Plot\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        name='EHR',\n",
    "        z=ehr_prob_df.values,\n",
    "        x=ehr_prob_df.columns,\n",
    "        y=list(range(len(ehr_prob_df.index))),\n",
    "        **heatmap_params\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    tickvals=list(range(len(ehr_prob_df.index))),\n",
    "    ticktext=ehr_prob_df.index,\n",
    "    autorange='reversed', type='category',\n",
    "    row=1, col=2,\n",
    "    **yaxes_params\n",
    ")\n",
    "\n",
    "# Horizontal separations\n",
    "for i in range(TOP_K, ehr_prob_df.shape[0], TOP_K):\n",
    "    fig.add_hline(\n",
    "        y = i - 0.5,\n",
    "        line_width=4,\n",
    "        line_color='white'\n",
    "    )\n",
    "\n",
    "# Adjust vertical title location\n",
    "for annotation in fig['layout']['annotations']:\n",
    "    annotation['y'] += 0.01\n",
    "\n",
    "fig.show()"
   ],
   "id": "60ae96bb3a94f8fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "beta_sc = model.etm_model.dec_sc.get_beta()      # K × 4340\n",
    "beta_ehr = model.etm_model.dec_ehr.get_beta()      # K × 4340\n",
    "\n",
    "uniq_top1_sc = np.unique(beta_sc.numpy(force=True).argmax(1)).size\n",
    "uniq_top1_ehr = np.unique(beta_ehr.numpy(force=True).argmax(1)).size\n",
    "print(f'unique top-1 tokens: sc = {uniq_top1_sc}/{beta_sc.shape[0]}, ehr = {uniq_top1_ehr}/{beta_ehr.shape[0]}')\n",
    "\n",
    "entropy_sc = -(beta_sc * beta_sc.clamp_min(1e-9).log()).sum(1)\n",
    "entropy_ehr = -(beta_ehr * beta_ehr.clamp_min(1e-9).log()).sum(1)\n",
    "print(f'entropy per topic: sc = {entropy_sc.numpy(force=True)}, ehr = {entropy_ehr.numpy(force=True)}')"
   ],
   "id": "7a72936d778800a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "### OCCURRENCE COUNT\n",
    "TOP_N = 25\n",
    "\n",
    "gene_counts = sc_prob_df.index.value_counts()\n",
    "icd_counts  = ehr_prob_df.index.value_counts()\n",
    "\n",
    "gene_counts_top = gene_counts.head(TOP_N)\n",
    "icd_counts_top  = icd_counts.head(TOP_N)\n",
    "\n",
    "# fig_num_topic = make_subplots(\n",
    "#     rows=1, cols=2,\n",
    "#     shared_xaxes=False,\n",
    "#     # horizontal_spacing=0.06,\n",
    "#     subplot_titles=[f'Top {TOP_N} genes by num_topics (K={K})', f'Top {TOP_N} ICD-9 codes by num_topics (K={K})']\n",
    "# )\n",
    "#\n",
    "# fig_num_topic.update_layout(\n",
    "#     template='plotly_white',\n",
    "#     font=dict(color='black', size=10)\n",
    "# )\n",
    "#\n",
    "# fig_num_topic.add_bar() # TODO: Got lazy.\n",
    "\n",
    "fig_gene_count = px.bar(\n",
    "    gene_counts_top.sort_values(ascending=False).reset_index(),\n",
    "    x='index', y='count',\n",
    "    title=f'Top {TOP_N} genes by num_topics (K={TOP_N})'\n",
    ")\n",
    "\n",
    "fig_icd_count = px.bar(\n",
    "    icd_counts_top.sort_values(ascending=False).reset_index(),\n",
    "    x='index', y='count',\n",
    "    title=f'Top {TOP_N} ICD-9 codes by num_topics (K={TOP_N})'\n",
    ")\n",
    "\n",
    "### PROBABILITY WEIGHTED IMPORTANCE\n",
    "gene_weight = sc_prob_df.groupby(sc_prob_df.index).sum().sum(axis=1)\n",
    "icd_weight  = ehr_prob_df.groupby(ehr_prob_df.index).sum().sum(axis=1)\n",
    "\n",
    "gene_weight_top = gene_weight.sort_values(ascending=False).head(TOP_N)\n",
    "icd_weight_top  = icd_weight.sort_values(ascending=False).head(TOP_N)\n",
    "\n",
    "fig_gene_weight = px.bar(\n",
    "    gene_weight_top.reset_index(),\n",
    "    x='index', y=0,\n",
    "    title=f'Top {TOP_N} genes by cumulative beta-probability',\n",
    "    labels={'index':'Gene', 0:'Σ β'},\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_icd_weight = px.bar(\n",
    "    icd_weight_top.reset_index(),\n",
    "    x='index', y=0,\n",
    "    title=f'Top {TOP_N} ICD-9 codes by cumulative beta-probability',\n",
    "    labels={'index':'ICD-9', 0:'Σ β'},\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "### FORMAT FIGURES\n",
    "font_params = dict(color='black', size=12)\n",
    "for fig in [fig_gene_count, fig_icd_count, fig_gene_weight, fig_icd_weight]:\n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        font=font_params,\n",
    "        title_font=dict(color='black', size=16)\n",
    "    )\n",
    "    fig.update_xaxes(tickfont=font_params, title_font=dict(color='black', size=14))\n",
    "    fig.update_yaxes(tickfont=font_params, title_font=dict(color='black', size=14))\n",
    "\n",
    "fig_gene_count.show()\n",
    "fig_icd_count.show()\n",
    "fig_gene_weight.show()\n",
    "fig_icd_weight.show()\n",
    "\n",
    "\n",
    "############################################################################\n",
    "### CUMULATIVE VS UBIQUITY\n",
    "font_params = dict(color='black', size=12)\n",
    "\n",
    "fig_scatter = px.scatter(\n",
    "    data_frame = pd.DataFrame({\n",
    "        'term':  list(gene_counts.index) + list(icd_counts.index),\n",
    "        'num_topics':  gene_counts.tolist()    + icd_counts.tolist(),\n",
    "        'cum_beta': pd.concat([gene_weight, icd_weight]).values,\n",
    "        'type': ['Gene']*len(gene_counts) + ['ICD-9']*len(icd_counts)\n",
    "    })\n",
    "    .query('cum_beta > 0')\n",
    "    ,\n",
    "    x='num_topics', y='cum_beta',\n",
    "    color='type', # two colors = Genes vs ICD-9\n",
    "    hover_data=['term', 'num_topics', 'cum_beta'],\n",
    "    marginal_x='violin',\n",
    "    marginal_y='violin',\n",
    "    # log_y=True, # keeps long-tail terms visible\n",
    "    template='plotly_white',\n",
    "    title='Term ubiquity vs cumulative probability',\n",
    ")\n",
    "\n",
    "# Update visuals\n",
    "fig_scatter.update_layout(\n",
    "    font=font_params,\n",
    "    title_font=dict(color='black', size=16),\n",
    "    legend_title_text='Term type',\n",
    ")\n",
    "fig_scatter.update_xaxes(title_font=font_params, tickfont=font_params,\n",
    "                         rangemode='tozero')\n",
    "fig_scatter.update_yaxes(title_font=font_params, tickfont=font_params,\n",
    "                         rangemode='tozero')\n",
    "\n",
    "fig_scatter.show()"
   ],
   "id": "9c8f247941818897",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: Implement Plotly Clustergram.",
   "id": "9dd4fd3dfc3f7ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# DONE",
   "id": "1758aab5795437fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T02:30:32.022152Z",
     "start_time": "2025-07-12T02:30:31.457159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Quick Run config modifications\n",
    "# api = wandb.Api()\n",
    "#\n",
    "# run = api.run('loicduch-mcgill-university/GraphETM/h5sajbsy')\n",
    "# run.config['optimizer'] = {'lr_etm': None, 'lr_graph': None}\n",
    "# run.update()"
   ],
   "id": "2b4bd4e6fedae7a6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# DONE",
   "id": "cd0624d290733a66"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
